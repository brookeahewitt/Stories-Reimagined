# Stories-Reimagined

Download Ollama: https://ollama.com/

Get Llama 3.1: ollama pull llama3.1

To see list of Llama models downloaded: ollama list

Run the virtual environment: . ollama/Scripts/activate

Download Ollama: pip install ollama

Run the program

To deactive the virtual environment: . ollama/Scripts/deactivate

If the target machine actively refuses the connect, run "ollama serve" on a separate terminal and keep it open while running the code.

Helpful Links:

https://github.com/RamiKrispin/ollama-poc?tab=readme-ov-file

https://www.youtube.com/watch?v=sdwTN3d-KIQ
